# 説明欄

## requirements.txtのライブラリ一覧

- ```ajsonrpc==1.2.0```【JSON-RPCを使ったリモートプロシージャコールを実装するための軽量なライブラリ】
- ```annotated-types==0.7.0```【Pythonの型アノテーションをサポートするためのライブラリ】
- ```anyio==4.9.0```【非同期I/Oのための統一APIを提供するライブラリ】
- ```bottle==0.13.4```【軽量なWebフレームワークで、シンプルで高速なWebアプリケーションを作成するためのライブラリ】
- ```cachetools==5.5.2```【キャッシュ処理を支援するライブラリ】
- ```certifi==2025.6.15```【Mozillaのルート証明書を提供するライブラリ】
- ```charset-normalizer==3.4.2```【文字エンコーディングを検出し、標準化するためのライブラリ】
- ```click==8.1.7```【コマンドラインインターフェイスを作成するためのライブラリ】
- ```colorama==0.4.6```【ロスプラットフォームで色付きテキストをターミナルに出力するためのライブラリ】
- ```distro==1.9.0```【Linuxディストリビューションの情報を取得するためのライブラリ】
- ```filelock==3.18.0```【ファイルに対するロックを簡単に扱えるライブラリ】
- ```fsspec==2025.5.1```【ファイルシステムの抽象化を提供するライブラリ】
- ```google-ai-generativelanguage==0.6.15```【GoogleのAI技術を使って、生成的な言語モデルにアクセスするためのライブラリ】
- ```google-api-core==2.25.1```【Google Cloud APIを扱うための基本ライブラリ】
- ```google-api-python-client==2.175.0```【Google APIをPythonから操作するための公式クライアントライブラリ】
- ```google-auth==2.40.3```【Google Cloud APIの認証を行うためのライブラリ】
- ```google-auth-httplib2==0.2.0```【google-authとhttplib2を統合し、HTTPリクエスト時に認証情報を自動的に付加するためのライブラリ】
- ```google-generativeai==0.8.5```【Googleの生成型AIを利用するためのライブラリ】
- ```googleapis-common-protos==1.70.0```【Google APIの共通プロトコルバッファ定義を提供するライブラリ】
- ```grpcio==1.73.1```【GoogleのgRPCライブラリ】
- ```grpcio-status==1.71.2```【grpcioと共に使用されるステータスコードのライブラリ】
- ```h11==0.16.0```【HTTP/1.1を実装するための低レベルライブラリ】
- ```httpcore==1.0.9```【HTTP通信のコア機能を提供するライブラリ】
- ```httplib2==0.22.0```【HTTPクライアントライブラリ】
- ```httpx==0.28.1```【高速でモダンなHTTPクライアントライブラリ】
- ```idna==3.10```【IDNの処理を行うためのライブラリ】
- ```Jinja2==3.1.6```【Python用のテンプレートエンジンで、HTMLやXMLファイルに動的なコンテンツを埋め込む際に使用するライブラリ】
- ```jiter==0.10.0```【JITコンパイラを活用したライブラリ】
- ```llvmlite==0.44.0```【LLVMのPythonバインディングのライブラリ】
- ```MarkupSafe==3.0.2```【HTMLやXMLの特殊文字をエスケープするライブラリ】
- ```marshmallow==3.26.1```【Pythonのオブジェクトをシリアライズしたり、デシリアライズしたりするためのライブラリ】
- ```more-itertools==10.7.0```【itertoolsモジュールの拡張ライブラリ】
- ```mpmath==1.3.0```【高精度な浮動小数点演算を提供するライブラリ】
- ```networkx==3.5```【グラフ理論を扱うためのライブラリ】
- ```numba==0.61.2```【PythonコードをJITコンパイルして高速化するためのライブラリ】
- ```numpy==2.2.6```【数値計算を行うための基本的なライブラリ】
- ```openai==1.93.0```【OpenAIのAPIを利用するためのライブラリ】
- ```openai-whisper==20250625```【OpenAIの音声認識モデル「Whisper」をPythonから使用するためのライブラリ】
- ```packaging==25.0```【Pythonのパッケージに関する処理を行うライブラリ】
- ```platformio==6.1.18```【IoTや組み込みシステム向けの開発環境を提供するライブラリ】
- ```proto-plus==1.26.1```【Protocol BuffersのPythonバインディングのライブラリ】
- ```protobuf==5.29.5```【GoogleのProtocol BuffersをPythonで使うためのライブラリ】
- ```pyasn1==0.6.1```【ASN.1形式のデータを処理するためのライブラリ】
- ```pyasn1_modules==0.4.2```【ASN.1データをより簡単に扱うための追加機能のライブラリ】
- ```pydantic==2.11.7```【データのバリデーションと設定管理を行うライブラリ】
- ```pydantic_core==2.33.2```【pydanticのコアライブラリ】
- ```pyelftools==0.32```【ELFファイルを解析するためのライブラリ】
- ```pyparsing==3.2.3```【パーサーを構築するためのライブラリ】
- ```pyserial==3.5```【シリアルポートの通信を行うためのライブラリ】
- ```regex==2024.11.6```【正規表現を使った文字列操作を行うためのライブラリ】
- ```requests==2.32.4```【HTTPリクエストを簡単に扱うためのライブラリ】
- ```rsa==4.9.1```【RSA暗号の実装ライブラリ】
- ```semantic-version==2.10.0```【セマンティックバージョニングを扱うためのライブラリ】
- ```sniffio==1.3.1```【現在使用している非同期I/Oライブラリを検出するためのライブラリ】
- ```starlette==0.46.2```【ASGI対応の軽量なWebフレームワーク】
- ```sympy==1.14.0```【数式計算を行うためのライブラリ】
- ```tabulate==0.9.0```【ターミナルでテーブル形式のデータを表示するためのライブラリ】
- ```tiktoken==0.9.0```【OpenAIのトークン化ライブラリ】
- ```torch==2.7.1```【深層学習フレームワークで、モデルのトレーニングや推論に使うライブラリ】
- ```tqdm==4.67.1```【プログレスバーを表示するためのライブラリ】
- ```typing-inspection==0.4.1```【Type Hintを解析するためのライブラリ】
- ```typing_extensions==4.14.0```【新しいPythonの型ヒント機能を古いバージョンでも使えるようにするためのライブラリ】
- ```uritemplate==4.2.0```【URIテンプレートを解析・生成するためのライブラリ】
- ```urllib3==2.5.0```【HTTP通信を行うための低レベルライブラリ】
- ```uvicorn==0.34.3```【高性能なASGIサーバー】
- ```wsproto==1.2.0```【WebSocketプロトコルを実装するライブラリ】
- ```moviepy==2.2.1```【ython で動画を編集・作成するためのライブラリ】

-----------------------------------------------------------------------

## gemnerate_image.pyの一覧

<img width="512" height="512" alt="20250708_174308_photorealistic, high quality, 黒い犬" src="https://github.com/user-attachments/assets/9c9d9b08-99d8-47c2-aa61-9a121d5feb2d" />


### ライブラリインストール方法
- requirements.txtを入れる
- その後ターミナルでcdコマンドでgenerate_image.pyとrequirements.txtがあるフォルダに移動
  （例）cd path\to\your\gemini-env
- その後コマンドで```pip install -r requirements.txt```をするとすべてのインストールされる

### 操作方法

- ターミナルで```python generate_image.py```で起動する
- ターミナルで何を生成しますか？と出るのでそこに生成したいものをいう
（例）✅ 何を生成しますか？＞白い犬
- 保存先を変更する場合は```--output```または```-O```できる
  （例）```python generate_image.py -o my_creations```
  
### コード説明

#### generate_enhanced_prompts
```
def generate_enhanced_prompts(user_prompt: str, gemini_model) -> tuple[str, str]:
    """
    Geminiを使用して、ユーザーの簡単なプロンプトを詳細な英語のプロンプトとネガティブプロンプトに変換します。
    """
    # Geminiによるプロンプト強化処理
```
- ```instruction```で、Geminiモデルに渡すプロンプトの内容を準備し、このプロンプトは、ユーザーの入力に基づいて高品質な画像生成用の詳細なプロンプトを生成するようGeminiに指示している
- ```gemini_model.generate_content(instruction)``` を使ってGeminiモデルに指示を送る
- Geminiからの返答はJSON形式で、これを解析し、プロンプトとネガティブプロンプトを抽出する

#### generate_and_save_image
```
def generate_and_save_image(pipe, prompt: str, negative_prompt: str, save_folder: str):
    """
    ロード済みのStable Diffusionパイプラインを使用して画像を生成し、指定されたフォルダに保存します。
    """
    # Stable Diffusionで画像を生成し保存する処理
```
- ```ipe(prompt, negative_prompt=negative_prompt) ```の部分で、Stable Diffusionモデルにプロンプトとネガティブプロンプトを渡して画像を生成する
- ```datetime.now().strftime("%Y%m%d_%H%M%S")```とプロンプトに基づいて生成されます。これにより、生成された画像が名前で保存する。

#### main
```
def main():
    """スクリプトのメイン処理"""
    load_dotenv()  # .envファイルから環境変数を読み込む
    parser = argparse.ArgumentParser(
        description="Stable Diffusionを使って対話形式で画像を生成し、保存します。",
        formatter_class=argparse.RawTextHelpFormatter
    )
    # コマンドライン引数の設定
```
- ```load_dotenv() ```を使って.envファイルからAPIキーやその他の設定を読み込む
- ```argparse```ライブラリを使って、コマンドライン引数を設定する
- ```GOOGLE_API_KEY```が設定されている場合、Gemini APIを初期化し、プロンプト強化機能を有効にする
- ```StableDiffusionPipeline.from_pretrained()```で、指定されたモデル（model_id）をロードする

#### 必要なこと

**1**.プロジェクトフォルダに移動し、仮想環境を作成する。

```

cd C:\Users\mitsuyuki-kurashiki\gemini-env
python -m venv venv

```

**2**.2回目以降は毎回仮想環境を有効化する

```

.\venv\Scripts\Activate.ps1

```

**3**.Pythonライブラリをインストール

```

pip install torch diffusers transformers accelerate Pillow python-dotenv google-generativeai

```

#### APIキーの設定

```

GOOGLE_API_KEY=""

```

#### 起動コマンド

```

python generate_image.py

```

------------------------------------------------------------------

## gemini_test.pyの一覧

#### ライブラリインストール方法

- ```pip install torch torchvision torchaudio```
- ```pip install diffusers```
- ```pip install transformers```
- ```pip install accelerate```
- ```pip install google-generativeai```
- ```pip install python-dotenv ```
- ```pip install Pillow```

### 概要
- Geminiを使ってプロンプトを高品質化
- Stable Diffusionで画像を生成
- 画像を指定フォルダに保存
- 対話ループで連続的に画像生成が可能

### コード説明

#### APIキーの設定
```
    api_key = os.getenv("GOOGLE_API_KEY")
    if not api_key:
        print("❌ エラー: 環境変数 'GOOGLE_API_KEY' が設定されていません。", file=sys.stderr)
        print("💡 ヒント: .envファイルに GOOGLE_API_KEY='あなたのキー' を追加してください。", file=sys.stderr)
        sys.exit(1)
```
- ```.env``` ファイルから ```GOOGLE_API_KEY``` を取得し、それが設定されていない場合はエラーメッセージを出力してプログラムを終了

#### チャットセッションの開始
```
    try:
        model = genai.GenerativeModel('gemini-1.0-pro')
        # 会話履歴を保持するチャットセッションを開始
        chat = model.start_chat(history=[])
```
- ```gemini-1.0-pro```という名前のGeminiモデルをロードし、```start_chat()```を呼び出してチャットセッションを開始する

#### ユーザーとの対話ループ
```
        print("🤖 Geminiとの対話を開始します。(終了するには 'quit' または 'exit' と入力してください)")

        while True:
            prompt = input("You: ")

            if prompt.lower() in ["quit", "exit"]:
                print("\n👋 対話を終了します。")
                break
```
- ユーザーと対話を続けるためのループが始まり、```quit```または```exit```と入力することで、対話を終了できる

#### Gemini APIへのリクエストとレスポンス表示
```
            print("Gemini: ", end="", flush=True)
            response = chat.send_message(prompt, stream=True)
            for chunk in response:
                print(chunk.text, end="", flush=True)
            print() # 改行
```
- ユーザーの入力を```chat.send_message()```メソッドを使ってGemini APIに送信し、そのレスポンスを受け取る

#### 必要なこと

- **1**.プロジェクトフォルダに移動し、仮想環境を作成する。

```

cd C:\Users\・・・・・\gemini-env
python -m venv venv

```

**2**.2回目以降は毎回仮想環境を有効化する

```

.\venv\Scripts\Activate.ps1

```


  -------------------------------------------------------------------------

## gemini_Whissperの一覧

### ライブラリインストール
- ```pip install -U openai-whisper```
- ```pip install moviepy```
- [ffmpeg](https://ffmpeg.org/download.html)を入れる</br>
  ・入れた後```ffmpeg -version```をターミナルで確認して出てればよい

### 概要
- Whisperを使って動画ファイルや音声ファイルから日本語の文字おこしするため
- **AudioTranscripts**に動画で音としてでてた内容を文字として保存する
- 保存先を変更する場合は```--output```または```-O```できる
- mp4フォルダに動画あればファイル名の指定だけでできる

### コード説明

#### moviepyのインポートとエラーチェック
```
try:
    from moviepy import VideoFileClip
except ImportError:
    print("❌ エラー: 'moviepy'ライブラリが見つかりません。", file=sys.stderr)
    print("💡 ヒント: 'pip install moviepy' を実行してインストールしてください。", file=sys.stderr)
    sys.exit(1)
```
- ```moviepy```は動画処理ライブラリで音声を抽出するために
- ```try-except```はmoviepyがインポートできなかったら、エラーメッセージを表示してプログラムを終了する。

#### Whisperモデルのロードと文字起こし

```
print(f"🔄 モデル '{model_name}' をロードしています...")
model = whisper.load_model(model_name)
print(f"🎤 '{os.path.basename(media_path)}' の文字起こしを開始します... (これには時間がかかる場合があります)")
result = model.transcribe(audio_path_to_transcribe, language="ja", fp16=False)
```
- Whisperモデルをロードし、音声ファイルを```language="ja"```は日本語で文字起こしを行う
- ```fp16=False```は、CPUで実行する際に精度を安定させるオプション

#### main関数の処理

```
if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Whisperで音声ファイルや動画ファイルを文字起こしします。")
    parser.add_argument("media_file", help="文字起こしする音声または動画ファイル。ファイル名のみ指定した場合、'mp4'フォルダ内を検索します。 (例: 'my_video.mp4' または 'C:\\videos\\my_video.mp4')")
    parser.add_argument("-m", "--model", default="base", choices=["tiny", "base", "small", "medium", "large"], help="使用するモデル")
    parser.add_argument("-o", "--output", help="文字起こし結果を保存するテキストファイルのパス。指定しない場合、'AudioTranscripts'フォルダに自動で保存されます。")

    args = parser.parse_args()
```
- ```argparse.ArgumentParser```を使って、コマンドライン引数を設定
- ```media_file```は文字起こし対象の音声または動画ファイルをする
- ```-m```/```--model```は使用するWhisperのモデル
- ```-o```/```--output```は文字起こし結果を保存するファイルパス

#### 入力ファイルと出力ファイルのパスを解決
```
input_media_path = args.media_file
if not os.path.isabs(input_media_path) and os.path.basename(input_media_path) == input_media_path:
    potential_path = os.path.join(script_dir, "mp4", input_media_path)
    if os.path.exists(potential_path):
        input_media_path = potential_path
        print(f"ℹ️ 'mp4'フォルダからファイル '{os.path.basename(input_media_path)}' を読み込みます。")
```
- 入力されたファイルパスが相対パスであった場合、スクリプトがあるディレクトリの```mp4```フォルダ内を検索してファイルを見つける
```
output_path = args.output
if output_path is None:
    save_folder = os.path.join(script_dir, "AudioTranscripts")
    os.makedirs(save_folder, exist_ok=True)
    base_filename = os.path.basename(input_media_path)
    filename_without_ext = os.path.splitext(base_filename)[0]
    output_filename = f"{filename_without_ext}.txt"
    output_path = os.path.join(save_folder, output_filename)
```
- 出力ファイルのパスが指定されていない場合、```AudioTranscripts```フォルダに自動でファイルを保存する。
#### メイン処理の実行
```
transcribe_media(input_media_path, args.model, output_path)
```
- ```transcribe_media```関数を呼び出して、実際の文字起こしを行う

#### やり方

**1**.プロジェクトフォルダに移動し、仮想環境を作成する。

```

cd C:\Users\mitsuyuki-kurashiki\gemini-env
python -m venv venv

```

**2**.2回目以降は毎回仮想環境を有効化する

```

.\venv\Scripts\Activate.ps1

```

**3**.ライブラリをインストールする 

```

pip install openai-whisper moviepy torch

```

**4**.requirements.txtのものをインストール

```

pip install -r requirements.txt

```

**5**.ffmpegインストール
- (ffmpeg)[https://ffmpeg.org/download.html]公式サイトでダウンロード
- ffmpegの解凍後、その保存した場所のパスを```FFMPEG_PATH=""```に追加する
- ```.env```にあるAPIキーを自分のを入れる```GOOGLE_API_KEY=""```


