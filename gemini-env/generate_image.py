import torch
from diffusers import StableDiffusionPipeline
import os
import sys
from datetime import datetime
import argparse
import re
import google.generativeai as genai
from PIL import Image
from dotenv import load_dotenv
import json
import uuid
import time
from typing import Tuple

def save_image(image, save_folder, prompt):
    """ç”»åƒã‚’ä¿å­˜ã™ã‚‹å‡¦ç†ã‚’åˆ¥é–¢æ•°ã«åˆ‡ã‚Šå‡ºã—"""
    os.makedirs(save_folder, exist_ok=True)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    prompt_slug = re.sub(r'[\\/*?:"<>|]', "", prompt)[:40]  # 40æ–‡å­—ã«åˆ¶é™
    unique_id = uuid.uuid4().hex[:6]  # ãƒ¦ãƒ‹ãƒ¼ã‚¯IDã‚’ç”Ÿæˆ
    filename = f"{timestamp}_{prompt_slug}_{unique_id}.png"
    save_path = os.path.join(save_folder, filename)
    image.save(save_path)
    print(f"âœ… ç”»åƒã‚’ä¿å­˜ã—ã¾ã—ãŸ: {save_path}")

def generate_enhanced_prompts(user_prompt: str, gemini_model) -> Tuple[str, str]:
    """Geminiã§ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å¼·åŒ–"""
    print("ğŸ¤– GeminiãŒæœ€é©ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è€ƒãˆã¦ã„ã¾ã™...")
    try:
        instruction = f"""ã‚ãªãŸã¯ã€Stable Diffusionã®ã‚ˆã†ãªç”»åƒç”ŸæˆAIã®ãŸã‚ã®ã€ä¸–ç•Œæœ€é«˜ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã§ã™ã€‚
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç°¡å˜ãªæ—¥æœ¬èªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ã€é«˜å“è³ªãªç”»åƒã‚’ç”Ÿæˆã™ã‚‹ãŸã‚ã®ã€è©³ç´°ã§å…·ä½“çš„ãªè‹±èªã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«å¤‰æ›ã—ã¦ãã ã•ã„ã€‚

# æŒ‡ç¤º
- ä»¥ä¸‹ã®JSONå½¢å¼ã§ã€ãƒã‚¸ãƒ†ã‚£ãƒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚
- ãƒã‚¸ãƒ†ã‚£ãƒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«ã¯ã€è¢«å†™ä½“ã€ç”»é¢¨ã€æ§‹å›³ã€èƒŒæ™¯ã€ç…§æ˜ã€è‰²ä½¿ã„ã€é›°å›²æ°—ãªã©ã‚’è©³ç´°ã«è¨˜è¿°ã—ã¦ãã ã•ã„ã€‚å‚‘ä½œ(masterpiece)ã€æœ€é«˜å“è³ª(best quality)ãªã©ã®å“è³ªã‚’å‘ä¸Šã•ã›ã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å¿…ãšå«ã‚ã¦ãã ã•ã„ã€‚
- ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«ã¯ã€ç”Ÿæˆã—ã¦ã»ã—ããªã„è¦ç´ ï¼ˆä¾‹ï¼šä½å“è³ªã€ä¸é®®æ˜ã€å¤‰å½¢ã€ãƒ†ã‚­ã‚¹ãƒˆã€ç½²åãªã©ï¼‰ã‚’å…·ä½“çš„ã«è¨˜è¿°ã—ã¦ãã ã•ã„ã€‚

# ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
{user_prompt}

# å‡ºåŠ›å½¢å¼ (JSON)
{{
  "prompt": "ã“ã“ã«ãƒã‚¸ãƒ†ã‚£ãƒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆ",
  "negative_prompt": "ã“ã“ã«ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆ"
}}
"""
        response = gemini_model.generate_content(instruction)        
        # Geminiã‹ã‚‰ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã¯ .text ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã«ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦æ ¼ç´ã•ã‚Œã¾ã™ã€‚
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§JSONå½¢å¼ã®å‡ºåŠ›ã‚’æŒ‡ç¤ºã—ã¦ã„ã‚‹ã®ã§ã€.text ã®å†…å®¹ã‚’ãƒ‘ãƒ¼ã‚¹ã—ã¾ã™ã€‚
        if response.text:
            # ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã®ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯(` ```json ... ``` `)ã‚’å‰Šé™¤
            cleaned_text = re.sub(r'```json\s*(.*?)\s*```', r'\1', response.text, flags=re.DOTALL)
            prompts = json.loads(cleaned_text.strip())

            # å¼·åŒ–ã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç¢ºèª
            print(f"âœ¨ ãƒã‚¸ãƒ†ã‚£ãƒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {prompts.get('prompt', '')}")
            print(f"ğŸš« ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {prompts.get('negative_prompt', '')}")            
            return prompts['prompt'], prompts['negative_prompt']
        else:
            print("âš ï¸ Geminiã‹ã‚‰é©åˆ‡ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
            return f"masterpiece, best quality, photorealistic, {user_prompt}", "deformed, disfigured, ugly, blurry, low quality, low-res, text, watermark, signature, username"

    except Exception as e:
        print(f"âš ï¸ Geminiã§ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {e}", file=sys.stderr)
        return f"masterpiece, best quality, photorealistic, {user_prompt}", "deformed, disfigured, ugly, blurry, low quality, low-res, text, watermark, signature, username"

def generate_and_save_image(pipe, prompt: str, negative_prompt: str, save_folder: str, guidance_scale: float, num_inference_steps: int):
    """ç”»åƒã‚’ç”Ÿæˆã—ä¿å­˜ã™ã‚‹å‡¦ç†"""
    try:
        print("-" * 20)
        print(f"ğŸ¨ '{prompt}' ã®ç”»åƒã‚’ç”Ÿæˆã—ã¦ã„ã¾ã™...")
        image = pipe(prompt, negative_prompt=negative_prompt, num_inference_steps=num_inference_steps, guidance_scale=guidance_scale).images[0]
        save_image(image, save_folder, prompt)
    except Exception as e:
        print(f"âŒ äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}", file=sys.stderr)

def main():
    """ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    load_dotenv()
    parser = argparse.ArgumentParser(description="ç”»åƒç”Ÿæˆãƒ„ãƒ¼ãƒ«")
    parser.add_argument("-o", "--output", type=str, default="img", help="ä¿å­˜å…ˆãƒ•ã‚©ãƒ«ãƒ€")
    args = parser.parse_args()

    save_folder = os.path.abspath(args.output)

    # Stable Diffusionãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®èª­ã¿è¾¼ã¿
    # CPUã§å®Ÿè¡Œã™ã‚‹ãŸã‚ã€torch_dtype=torch.float16ã®æŒ‡å®šã‚’å‰Šé™¤
    pipe = StableDiffusionPipeline.from_pretrained("stabilityai/stable-diffusion-2-1-base")
    
    pipe.to("cpu")

    # Gemini APIåˆæœŸåŒ–
    genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))
    gemini_model = genai.GenerativeModel("gemini-1.5-flash")

    print("ç”»åƒã‚’ç”Ÿæˆã™ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆ'exit'ã§çµ‚äº†ï¼‰ã€‚")
    while True:
        user_prompt = input("ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: ").strip()
        if user_prompt.lower() in ['exit', 'quit']:
            print("çµ‚äº†ã—ã¾ã™ã€‚")
            break
        prompt, negative_prompt = generate_enhanced_prompts(user_prompt, gemini_model)
        generate_and_save_image(pipe, prompt, negative_prompt, save_folder, guidance_scale=8.0, num_inference_steps=50)

if __name__ == "__main__":
    main()
